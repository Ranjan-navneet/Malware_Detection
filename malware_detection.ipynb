{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Y5rr42Sfr6o"
      },
      "outputs": [],
      "source": [
        "#MOUNTING GOOGLE DRIVE\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "#UNMOUNT\n",
        "#drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#IMPORTS\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import *"
      ],
      "metadata": {
        "id": "NK7AXTSpgqE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA CLEANING\n",
        "\n",
        "#TRAINING & TESTING DATASETS - INITIAL\n",
        "\n",
        "training_dataset = pd.read_csv(\"/content/drive/MyDrive/datasets/malware_detection/ClaMP_Integrated-5184.csv\")\n",
        "testing_dataset = pd.read_csv(\"/content/drive/MyDrive/datasets/malware_detection/ClaMP_Raw-5184.csv\")"
      ],
      "metadata": {
        "id": "g7yZcy67jGTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# REMOVING EXTRA COLUMNS\n",
        "\n",
        "for i in training_dataset.columns:\n",
        "  if i not in testing_dataset.columns:\n",
        "    training_dataset = training_dataset.drop(i,axis=1)\n",
        "testing_dataset=testing_dataset[training_dataset.columns]"
      ],
      "metadata": {
        "id": "xFcytAz5kCr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING & TESTING DATASETS - SHUFFLED\n",
        "training_dataset = training_dataset.sample(frac = 1)\n",
        "testing_dataset = testing_dataset.sample(frac = 1)"
      ],
      "metadata": {
        "id": "Ke9hacYrgUxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING & TESTING DATASETS - FINAL\n",
        "\n",
        "total_records = len(training_dataset.index)+len(testing_dataset.index)\n",
        "training_records ,testing_records= round(total_records*0.80),round(total_records*0.20)\n",
        "training_dataset = training_dataset.append(testing_dataset.iloc[:len(testing_dataset.index)-testing_records],ignore_index=True)\n",
        "testing_dataset = testing_dataset.iloc[len(testing_dataset.index)-testing_records:]\n",
        "testing_dataset = testing_dataset.reset_index()\n",
        "\n",
        "#DATASET DISTRIBUTION \n",
        "plt.subplot(1,2,1)\n",
        "plt.hist(training_dataset[\"class\"])\n",
        "plt.title(\"training-set\")\n",
        "plt.subplot(1,2,2)\n",
        "plt.hist(testing_dataset[\"class\"])\n",
        "plt.title(\"testing-set\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "REOdepMPAkih",
        "outputId": "4ee031fc-f791-4d76-87c8-22805d56e505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'testing-set')"
            ]
          },
          "metadata": {},
          "execution_count": 98
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA EXPLORATION\n",
        "\n",
        "training_dataset.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQYpWFWbMrqj",
        "outputId": "c5c0ad40-8206-4021-b8f2-d359f3210054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8315 entries, 0 to 8314\n",
            "Data columns (total 35 columns):\n",
            " #   Column                       Non-Null Count  Dtype\n",
            "---  ------                       --------------  -----\n",
            " 0   e_cblp                       8315 non-null   int64\n",
            " 1   e_cp                         8315 non-null   int64\n",
            " 2   e_cparhdr                    8315 non-null   int64\n",
            " 3   e_maxalloc                   8315 non-null   int64\n",
            " 4   e_sp                         8315 non-null   int64\n",
            " 5   e_lfanew                     8315 non-null   int64\n",
            " 6   NumberOfSections             8315 non-null   int64\n",
            " 7   CreationYear                 8315 non-null   int64\n",
            " 8   MajorLinkerVersion           8315 non-null   int64\n",
            " 9   MinorLinkerVersion           8315 non-null   int64\n",
            " 10  SizeOfCode                   8315 non-null   int64\n",
            " 11  SizeOfInitializedData        8315 non-null   int64\n",
            " 12  SizeOfUninitializedData      8315 non-null   int64\n",
            " 13  AddressOfEntryPoint          8315 non-null   int64\n",
            " 14  BaseOfCode                   8315 non-null   int64\n",
            " 15  BaseOfData                   8315 non-null   int64\n",
            " 16  ImageBase                    8315 non-null   int64\n",
            " 17  SectionAlignment             8315 non-null   int64\n",
            " 18  FileAlignment                8315 non-null   int64\n",
            " 19  MajorOperatingSystemVersion  8315 non-null   int64\n",
            " 20  MinorOperatingSystemVersion  8315 non-null   int64\n",
            " 21  MajorImageVersion            8315 non-null   int64\n",
            " 22  MinorImageVersion            8315 non-null   int64\n",
            " 23  MajorSubsystemVersion        8315 non-null   int64\n",
            " 24  MinorSubsystemVersion        8315 non-null   int64\n",
            " 25  SizeOfImage                  8315 non-null   int64\n",
            " 26  SizeOfHeaders                8315 non-null   int64\n",
            " 27  CheckSum                     8315 non-null   int64\n",
            " 28  Subsystem                    8315 non-null   int64\n",
            " 29  SizeOfStackReserve           8315 non-null   int64\n",
            " 30  SizeOfStackCommit            8315 non-null   int64\n",
            " 31  SizeOfHeapReserve            8315 non-null   int64\n",
            " 32  SizeOfHeapCommit             8315 non-null   int64\n",
            " 33  LoaderFlags                  8315 non-null   int64\n",
            " 34  class                        8315 non-null   int64\n",
            "dtypes: int64(35)\n",
            "memory usage: 2.2 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING DATA : SEPERATING FEATURES AND LABELS\n",
        "\n",
        "feature = training_dataset.drop([\"class\"], axis = 1)\n",
        "label = training_dataset[\"class\"]\n",
        "# SCALING\n",
        "\n",
        "scaler = StandardScaler()\n",
        "feature = scaler.fit_transform(feature)\n",
        "#ONE HOT ENCODING\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label = label_encoder.fit_transform(label)\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "label = label.reshape(len(label), 1)\n",
        "label = onehot_encoder.fit_transform(label)\n",
        "feature_train, feature_test, label_train, label_test = train_test_split(feature,label, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "E8T5cmMnz7if"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL\n",
        "model = Sequential([\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(2, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])"
      ],
      "metadata": {
        "id": "JKS6QoXq78IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL TRAINING\n",
        "history = model.fit(feature_train, label_train,\n",
        "                           epochs = 200,\n",
        "                           batch_size = 64,\n",
        "                           validation_data = (feature_test, label_test),)"
      ],
      "metadata": {
        "id": "1Hp3Ej_yHytT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0016c38-934e-43bd-e32e-ab89d306a71b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "104/104 [==============================] - 3s 11ms/step - loss: 0.3714 - binary_accuracy: 0.8280 - val_loss: 0.5085 - val_binary_accuracy: 0.8860\n",
            "Epoch 2/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.2586 - binary_accuracy: 0.8907 - val_loss: 0.5674 - val_binary_accuracy: 0.8668\n",
            "Epoch 3/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.2366 - binary_accuracy: 0.8994 - val_loss: 0.7983 - val_binary_accuracy: 0.9146\n",
            "Epoch 4/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.2155 - binary_accuracy: 0.9150 - val_loss: 0.9764 - val_binary_accuracy: 0.9236\n",
            "Epoch 5/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.2108 - binary_accuracy: 0.9143 - val_loss: 1.5022 - val_binary_accuracy: 0.9131\n",
            "Epoch 6/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1932 - binary_accuracy: 0.9218 - val_loss: 1.8914 - val_binary_accuracy: 0.9164\n",
            "Epoch 7/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1929 - binary_accuracy: 0.9236 - val_loss: 1.3186 - val_binary_accuracy: 0.9059\n",
            "Epoch 8/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1837 - binary_accuracy: 0.9284 - val_loss: 1.2994 - val_binary_accuracy: 0.9116\n",
            "Epoch 9/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1830 - binary_accuracy: 0.9273 - val_loss: 1.4415 - val_binary_accuracy: 0.9197\n",
            "Epoch 10/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1779 - binary_accuracy: 0.9287 - val_loss: 1.5977 - val_binary_accuracy: 0.9372\n",
            "Epoch 11/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1745 - binary_accuracy: 0.9298 - val_loss: 1.7102 - val_binary_accuracy: 0.9390\n",
            "Epoch 12/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1656 - binary_accuracy: 0.9354 - val_loss: 1.1357 - val_binary_accuracy: 0.9381\n",
            "Epoch 13/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1646 - binary_accuracy: 0.9336 - val_loss: 1.1415 - val_binary_accuracy: 0.9351\n",
            "Epoch 14/200\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.1615 - binary_accuracy: 0.9354 - val_loss: 0.5032 - val_binary_accuracy: 0.9336\n",
            "Epoch 15/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1621 - binary_accuracy: 0.9361 - val_loss: 1.3677 - val_binary_accuracy: 0.9113\n",
            "Epoch 16/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1546 - binary_accuracy: 0.9387 - val_loss: 1.0024 - val_binary_accuracy: 0.9360\n",
            "Epoch 17/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1559 - binary_accuracy: 0.9384 - val_loss: 0.8654 - val_binary_accuracy: 0.9375\n",
            "Epoch 18/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1602 - binary_accuracy: 0.9371 - val_loss: 0.9431 - val_binary_accuracy: 0.9360\n",
            "Epoch 19/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1538 - binary_accuracy: 0.9387 - val_loss: 1.5725 - val_binary_accuracy: 0.9269\n",
            "Epoch 20/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1538 - binary_accuracy: 0.9383 - val_loss: 1.4775 - val_binary_accuracy: 0.9197\n",
            "Epoch 21/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1516 - binary_accuracy: 0.9413 - val_loss: 1.2209 - val_binary_accuracy: 0.9059\n",
            "Epoch 22/200\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 0.1473 - binary_accuracy: 0.9432 - val_loss: 1.3868 - val_binary_accuracy: 0.9354\n",
            "Epoch 23/200\n",
            "104/104 [==============================] - 1s 13ms/step - loss: 0.1452 - binary_accuracy: 0.9436 - val_loss: 2.1540 - val_binary_accuracy: 0.9308\n",
            "Epoch 24/200\n",
            "104/104 [==============================] - 1s 12ms/step - loss: 0.1516 - binary_accuracy: 0.9398 - val_loss: 1.3530 - val_binary_accuracy: 0.9197\n",
            "Epoch 25/200\n",
            "104/104 [==============================] - 1s 12ms/step - loss: 0.1420 - binary_accuracy: 0.9445 - val_loss: 1.0333 - val_binary_accuracy: 0.9311\n",
            "Epoch 26/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1511 - binary_accuracy: 0.9408 - val_loss: 1.3072 - val_binary_accuracy: 0.9236\n",
            "Epoch 27/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1455 - binary_accuracy: 0.9424 - val_loss: 1.3585 - val_binary_accuracy: 0.9215\n",
            "Epoch 28/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1414 - binary_accuracy: 0.9452 - val_loss: 1.4638 - val_binary_accuracy: 0.9032\n",
            "Epoch 29/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1448 - binary_accuracy: 0.9446 - val_loss: 1.1832 - val_binary_accuracy: 0.9149\n",
            "Epoch 30/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1337 - binary_accuracy: 0.9492 - val_loss: 1.1092 - val_binary_accuracy: 0.9369\n",
            "Epoch 31/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1390 - binary_accuracy: 0.9465 - val_loss: 1.4893 - val_binary_accuracy: 0.9167\n",
            "Epoch 32/200\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.1319 - binary_accuracy: 0.9475 - val_loss: 1.3194 - val_binary_accuracy: 0.9230\n",
            "Epoch 33/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1319 - binary_accuracy: 0.9490 - val_loss: 1.0760 - val_binary_accuracy: 0.9212\n",
            "Epoch 34/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1245 - binary_accuracy: 0.9514 - val_loss: 1.5109 - val_binary_accuracy: 0.9366\n",
            "Epoch 35/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1284 - binary_accuracy: 0.9529 - val_loss: 1.1635 - val_binary_accuracy: 0.9149\n",
            "Epoch 36/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1250 - binary_accuracy: 0.9500 - val_loss: 1.3676 - val_binary_accuracy: 0.9134\n",
            "Epoch 37/200\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.1282 - binary_accuracy: 0.9499 - val_loss: 2.0600 - val_binary_accuracy: 0.9287\n",
            "Epoch 38/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1254 - binary_accuracy: 0.9520 - val_loss: 1.7660 - val_binary_accuracy: 0.9308\n",
            "Epoch 39/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1259 - binary_accuracy: 0.9501 - val_loss: 1.4854 - val_binary_accuracy: 0.9330\n",
            "Epoch 40/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1225 - binary_accuracy: 0.9522 - val_loss: 1.6370 - val_binary_accuracy: 0.9381\n",
            "Epoch 41/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1180 - binary_accuracy: 0.9535 - val_loss: 1.4884 - val_binary_accuracy: 0.9236\n",
            "Epoch 42/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1326 - binary_accuracy: 0.9493 - val_loss: 1.9748 - val_binary_accuracy: 0.9348\n",
            "Epoch 43/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1273 - binary_accuracy: 0.9496 - val_loss: 1.3774 - val_binary_accuracy: 0.9372\n",
            "Epoch 44/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1298 - binary_accuracy: 0.9501 - val_loss: 1.0809 - val_binary_accuracy: 0.9197\n",
            "Epoch 45/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1218 - binary_accuracy: 0.9514 - val_loss: 1.3301 - val_binary_accuracy: 0.9116\n",
            "Epoch 46/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1266 - binary_accuracy: 0.9508 - val_loss: 1.6325 - val_binary_accuracy: 0.9342\n",
            "Epoch 47/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1284 - binary_accuracy: 0.9505 - val_loss: 1.2746 - val_binary_accuracy: 0.9290\n",
            "Epoch 48/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1207 - binary_accuracy: 0.9544 - val_loss: 1.1558 - val_binary_accuracy: 0.9227\n",
            "Epoch 49/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1267 - binary_accuracy: 0.9509 - val_loss: 2.1140 - val_binary_accuracy: 0.9302\n",
            "Epoch 50/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1233 - binary_accuracy: 0.9538 - val_loss: 2.2255 - val_binary_accuracy: 0.9140\n",
            "Epoch 51/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1164 - binary_accuracy: 0.9557 - val_loss: 0.6481 - val_binary_accuracy: 0.9161\n",
            "Epoch 52/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1256 - binary_accuracy: 0.9515 - val_loss: 1.4657 - val_binary_accuracy: 0.9330\n",
            "Epoch 53/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1126 - binary_accuracy: 0.9546 - val_loss: 1.8735 - val_binary_accuracy: 0.9209\n",
            "Epoch 54/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1108 - binary_accuracy: 0.9566 - val_loss: 3.1931 - val_binary_accuracy: 0.9164\n",
            "Epoch 55/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1167 - binary_accuracy: 0.9554 - val_loss: 2.7328 - val_binary_accuracy: 0.9134\n",
            "Epoch 56/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1190 - binary_accuracy: 0.9578 - val_loss: 2.4478 - val_binary_accuracy: 0.9293\n",
            "Epoch 57/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1121 - binary_accuracy: 0.9568 - val_loss: 1.9170 - val_binary_accuracy: 0.9125\n",
            "Epoch 58/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1139 - binary_accuracy: 0.9568 - val_loss: 2.2039 - val_binary_accuracy: 0.9191\n",
            "Epoch 59/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1202 - binary_accuracy: 0.9535 - val_loss: 1.7021 - val_binary_accuracy: 0.9176\n",
            "Epoch 60/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1222 - binary_accuracy: 0.9514 - val_loss: 1.6975 - val_binary_accuracy: 0.9296\n",
            "Epoch 61/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1175 - binary_accuracy: 0.9567 - val_loss: 2.2382 - val_binary_accuracy: 0.9143\n",
            "Epoch 62/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1135 - binary_accuracy: 0.9574 - val_loss: 2.3655 - val_binary_accuracy: 0.9158\n",
            "Epoch 63/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1041 - binary_accuracy: 0.9575 - val_loss: 2.3944 - val_binary_accuracy: 0.9080\n",
            "Epoch 64/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1145 - binary_accuracy: 0.9551 - val_loss: 1.9816 - val_binary_accuracy: 0.9080\n",
            "Epoch 65/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1110 - binary_accuracy: 0.9580 - val_loss: 2.7529 - val_binary_accuracy: 0.9074\n",
            "Epoch 66/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1093 - binary_accuracy: 0.9575 - val_loss: 1.7231 - val_binary_accuracy: 0.9230\n",
            "Epoch 67/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1066 - binary_accuracy: 0.9615 - val_loss: 2.5293 - val_binary_accuracy: 0.9185\n",
            "Epoch 68/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1118 - binary_accuracy: 0.9552 - val_loss: 3.2795 - val_binary_accuracy: 0.9212\n",
            "Epoch 69/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1116 - binary_accuracy: 0.9560 - val_loss: 1.7774 - val_binary_accuracy: 0.9281\n",
            "Epoch 70/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1051 - binary_accuracy: 0.9595 - val_loss: 3.0992 - val_binary_accuracy: 0.9071\n",
            "Epoch 71/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1148 - binary_accuracy: 0.9568 - val_loss: 2.6092 - val_binary_accuracy: 0.9218\n",
            "Epoch 72/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1048 - binary_accuracy: 0.9602 - val_loss: 1.6866 - val_binary_accuracy: 0.9161\n",
            "Epoch 73/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1123 - binary_accuracy: 0.9559 - val_loss: 2.1597 - val_binary_accuracy: 0.9143\n",
            "Epoch 74/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1050 - binary_accuracy: 0.9590 - val_loss: 1.8674 - val_binary_accuracy: 0.9104\n",
            "Epoch 75/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1045 - binary_accuracy: 0.9613 - val_loss: 4.5522 - val_binary_accuracy: 0.9152\n",
            "Epoch 76/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1141 - binary_accuracy: 0.9580 - val_loss: 2.4748 - val_binary_accuracy: 0.9164\n",
            "Epoch 77/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1018 - binary_accuracy: 0.9617 - val_loss: 2.6886 - val_binary_accuracy: 0.8863\n",
            "Epoch 78/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1085 - binary_accuracy: 0.9577 - val_loss: 3.8342 - val_binary_accuracy: 0.8794\n",
            "Epoch 79/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1120 - binary_accuracy: 0.9581 - val_loss: 3.2812 - val_binary_accuracy: 0.9080\n",
            "Epoch 80/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1042 - binary_accuracy: 0.9605 - val_loss: 2.4460 - val_binary_accuracy: 0.8990\n",
            "Epoch 81/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1065 - binary_accuracy: 0.9579 - val_loss: 2.0958 - val_binary_accuracy: 0.8960\n",
            "Epoch 82/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1052 - binary_accuracy: 0.9599 - val_loss: 2.0417 - val_binary_accuracy: 0.9020\n",
            "Epoch 83/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1020 - binary_accuracy: 0.9620 - val_loss: 2.1160 - val_binary_accuracy: 0.9125\n",
            "Epoch 84/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1075 - binary_accuracy: 0.9569 - val_loss: 1.9991 - val_binary_accuracy: 0.9092\n",
            "Epoch 85/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1033 - binary_accuracy: 0.9600 - val_loss: 1.9713 - val_binary_accuracy: 0.8969\n",
            "Epoch 86/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1043 - binary_accuracy: 0.9625 - val_loss: 2.7068 - val_binary_accuracy: 0.9182\n",
            "Epoch 87/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1051 - binary_accuracy: 0.9606 - val_loss: 2.0797 - val_binary_accuracy: 0.9002\n",
            "Epoch 88/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0959 - binary_accuracy: 0.9621 - val_loss: 2.6060 - val_binary_accuracy: 0.9086\n",
            "Epoch 89/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1093 - binary_accuracy: 0.9584 - val_loss: 2.7818 - val_binary_accuracy: 0.8996\n",
            "Epoch 90/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1053 - binary_accuracy: 0.9600 - val_loss: 2.2321 - val_binary_accuracy: 0.8951\n",
            "Epoch 91/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1035 - binary_accuracy: 0.9599 - val_loss: 1.9452 - val_binary_accuracy: 0.9104\n",
            "Epoch 92/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0991 - binary_accuracy: 0.9635 - val_loss: 2.5809 - val_binary_accuracy: 0.9203\n",
            "Epoch 93/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0895 - binary_accuracy: 0.9679 - val_loss: 2.4739 - val_binary_accuracy: 0.8704\n",
            "Epoch 94/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0981 - binary_accuracy: 0.9628 - val_loss: 2.4025 - val_binary_accuracy: 0.9038\n",
            "Epoch 95/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1042 - binary_accuracy: 0.9616 - val_loss: 2.6150 - val_binary_accuracy: 0.8912\n",
            "Epoch 96/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0910 - binary_accuracy: 0.9650 - val_loss: 3.1968 - val_binary_accuracy: 0.8951\n",
            "Epoch 97/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1005 - binary_accuracy: 0.9611 - val_loss: 2.9461 - val_binary_accuracy: 0.9170\n",
            "Epoch 98/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0934 - binary_accuracy: 0.9650 - val_loss: 2.9984 - val_binary_accuracy: 0.9041\n",
            "Epoch 99/200\n",
            "104/104 [==============================] - 1s 11ms/step - loss: 0.1006 - binary_accuracy: 0.9617 - val_loss: 2.1126 - val_binary_accuracy: 0.9125\n",
            "Epoch 100/200\n",
            "104/104 [==============================] - 1s 12ms/step - loss: 0.0950 - binary_accuracy: 0.9623 - val_loss: 2.3568 - val_binary_accuracy: 0.8839\n",
            "Epoch 101/200\n",
            "104/104 [==============================] - 1s 12ms/step - loss: 0.0892 - binary_accuracy: 0.9663 - val_loss: 2.3803 - val_binary_accuracy: 0.8960\n",
            "Epoch 102/200\n",
            "104/104 [==============================] - 1s 12ms/step - loss: 0.0967 - binary_accuracy: 0.9632 - val_loss: 2.4976 - val_binary_accuracy: 0.9164\n",
            "Epoch 103/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1011 - binary_accuracy: 0.9614 - val_loss: 1.9057 - val_binary_accuracy: 0.9014\n",
            "Epoch 104/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0909 - binary_accuracy: 0.9656 - val_loss: 2.1439 - val_binary_accuracy: 0.9014\n",
            "Epoch 105/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0943 - binary_accuracy: 0.9646 - val_loss: 2.2612 - val_binary_accuracy: 0.8764\n",
            "Epoch 106/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0865 - binary_accuracy: 0.9650 - val_loss: 2.5549 - val_binary_accuracy: 0.8755\n",
            "Epoch 107/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0992 - binary_accuracy: 0.9633 - val_loss: 1.8271 - val_binary_accuracy: 0.9002\n",
            "Epoch 108/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0923 - binary_accuracy: 0.9628 - val_loss: 3.2346 - val_binary_accuracy: 0.8413\n",
            "Epoch 109/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0974 - binary_accuracy: 0.9620 - val_loss: 3.1934 - val_binary_accuracy: 0.8815\n",
            "Epoch 110/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1035 - binary_accuracy: 0.9608 - val_loss: 2.8637 - val_binary_accuracy: 0.9104\n",
            "Epoch 111/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0926 - binary_accuracy: 0.9637 - val_loss: 3.0436 - val_binary_accuracy: 0.8839\n",
            "Epoch 112/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.0957 - binary_accuracy: 0.9644 - val_loss: 2.3315 - val_binary_accuracy: 0.8665\n",
            "Epoch 113/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0967 - binary_accuracy: 0.9637 - val_loss: 5.2772 - val_binary_accuracy: 0.9038\n",
            "Epoch 114/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0981 - binary_accuracy: 0.9644 - val_loss: 4.2534 - val_binary_accuracy: 0.9020\n",
            "Epoch 115/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0925 - binary_accuracy: 0.9641 - val_loss: 4.1572 - val_binary_accuracy: 0.8912\n",
            "Epoch 116/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0963 - binary_accuracy: 0.9633 - val_loss: 2.5393 - val_binary_accuracy: 0.8629\n",
            "Epoch 117/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.0893 - binary_accuracy: 0.9660 - val_loss: 3.1327 - val_binary_accuracy: 0.8662\n",
            "Epoch 118/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0933 - binary_accuracy: 0.9619 - val_loss: 3.7651 - val_binary_accuracy: 0.8605\n",
            "Epoch 119/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0948 - binary_accuracy: 0.9615 - val_loss: 2.4197 - val_binary_accuracy: 0.8725\n",
            "Epoch 120/200\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.0896 - binary_accuracy: 0.9670 - val_loss: 5.0328 - val_binary_accuracy: 0.9002\n",
            "Epoch 121/200\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.0931 - binary_accuracy: 0.9641 - val_loss: 3.6348 - val_binary_accuracy: 0.8818\n",
            "Epoch 122/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0892 - binary_accuracy: 0.9675 - val_loss: 1.5110 - val_binary_accuracy: 0.8818\n",
            "Epoch 123/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0872 - binary_accuracy: 0.9674 - val_loss: 2.8005 - val_binary_accuracy: 0.9020\n",
            "Epoch 124/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0923 - binary_accuracy: 0.9632 - val_loss: 2.7494 - val_binary_accuracy: 0.9125\n",
            "Epoch 125/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0888 - binary_accuracy: 0.9643 - val_loss: 1.9601 - val_binary_accuracy: 0.9002\n",
            "Epoch 126/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0918 - binary_accuracy: 0.9645 - val_loss: 3.3057 - val_binary_accuracy: 0.8918\n",
            "Epoch 127/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0920 - binary_accuracy: 0.9642 - val_loss: 3.9174 - val_binary_accuracy: 0.8755\n",
            "Epoch 128/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0901 - binary_accuracy: 0.9669 - val_loss: 3.2159 - val_binary_accuracy: 0.8455\n",
            "Epoch 129/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.0826 - binary_accuracy: 0.9655 - val_loss: 3.8837 - val_binary_accuracy: 0.8551\n",
            "Epoch 130/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.0872 - binary_accuracy: 0.9678 - val_loss: 3.6372 - val_binary_accuracy: 0.8710\n",
            "Epoch 131/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.0889 - binary_accuracy: 0.9649 - val_loss: 3.6059 - val_binary_accuracy: 0.8815\n",
            "Epoch 132/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.0883 - binary_accuracy: 0.9685 - val_loss: 1.6557 - val_binary_accuracy: 0.8942\n",
            "Epoch 133/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0961 - binary_accuracy: 0.9629 - val_loss: 3.7739 - val_binary_accuracy: 0.8629\n",
            "Epoch 134/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0845 - binary_accuracy: 0.9690 - val_loss: 3.8592 - val_binary_accuracy: 0.8791\n",
            "Epoch 135/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0895 - binary_accuracy: 0.9693 - val_loss: 3.9082 - val_binary_accuracy: 0.8782\n",
            "Epoch 136/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.0859 - binary_accuracy: 0.9666 - val_loss: 2.7011 - val_binary_accuracy: 0.8632\n",
            "Epoch 137/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0930 - binary_accuracy: 0.9656 - val_loss: 2.7950 - val_binary_accuracy: 0.8491\n",
            "Epoch 138/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.0889 - binary_accuracy: 0.9664 - val_loss: 3.1130 - val_binary_accuracy: 0.8521\n",
            "Epoch 139/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0843 - binary_accuracy: 0.9666 - val_loss: 2.8665 - val_binary_accuracy: 0.8548\n",
            "Epoch 140/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.0818 - binary_accuracy: 0.9711 - val_loss: 3.2718 - val_binary_accuracy: 0.8593\n",
            "Epoch 141/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0909 - binary_accuracy: 0.9660 - val_loss: 3.6692 - val_binary_accuracy: 0.8761\n",
            "Epoch 142/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0919 - binary_accuracy: 0.9653 - val_loss: 3.7151 - val_binary_accuracy: 0.8644\n",
            "Epoch 143/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.0819 - binary_accuracy: 0.9701 - val_loss: 3.6872 - val_binary_accuracy: 0.8680\n",
            "Epoch 144/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0817 - binary_accuracy: 0.9694 - val_loss: 2.5106 - val_binary_accuracy: 0.8635\n",
            "Epoch 145/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.0795 - binary_accuracy: 0.9673 - val_loss: 2.6833 - val_binary_accuracy: 0.8779\n",
            "Epoch 146/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0885 - binary_accuracy: 0.9663 - val_loss: 2.9323 - val_binary_accuracy: 0.8827\n",
            "Epoch 147/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.0850 - binary_accuracy: 0.9668 - val_loss: 2.3849 - val_binary_accuracy: 0.8413\n",
            "Epoch 148/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0862 - binary_accuracy: 0.9663 - val_loss: 3.3889 - val_binary_accuracy: 0.8842\n",
            "Epoch 149/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0892 - binary_accuracy: 0.9660 - val_loss: 3.8246 - val_binary_accuracy: 0.8464\n",
            "Epoch 150/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0871 - binary_accuracy: 0.9674 - val_loss: 4.4131 - val_binary_accuracy: 0.8644\n",
            "Epoch 151/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0832 - binary_accuracy: 0.9683 - val_loss: 4.2020 - val_binary_accuracy: 0.9008\n",
            "Epoch 152/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.0868 - binary_accuracy: 0.9678 - val_loss: 4.0732 - val_binary_accuracy: 0.8746\n",
            "Epoch 153/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0842 - binary_accuracy: 0.9671 - val_loss: 3.2095 - val_binary_accuracy: 0.8563\n",
            "Epoch 154/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0818 - binary_accuracy: 0.9692 - val_loss: 3.9285 - val_binary_accuracy: 0.8894\n",
            "Epoch 155/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0843 - binary_accuracy: 0.9671 - val_loss: 4.1129 - val_binary_accuracy: 0.8521\n",
            "Epoch 156/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0873 - binary_accuracy: 0.9665 - val_loss: 3.3145 - val_binary_accuracy: 0.8635\n",
            "Epoch 157/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0855 - binary_accuracy: 0.9681 - val_loss: 3.7813 - val_binary_accuracy: 0.8782\n",
            "Epoch 158/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0861 - binary_accuracy: 0.9692 - val_loss: 2.8331 - val_binary_accuracy: 0.9098\n",
            "Epoch 159/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0875 - binary_accuracy: 0.9681 - val_loss: 3.7376 - val_binary_accuracy: 0.8419\n",
            "Epoch 160/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0836 - binary_accuracy: 0.9660 - val_loss: 4.3741 - val_binary_accuracy: 0.8857\n",
            "Epoch 161/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0783 - binary_accuracy: 0.9693 - val_loss: 3.3045 - val_binary_accuracy: 0.8857\n",
            "Epoch 162/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.0831 - binary_accuracy: 0.9695 - val_loss: 2.6450 - val_binary_accuracy: 0.8815\n",
            "Epoch 163/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0816 - binary_accuracy: 0.9678 - val_loss: 2.9864 - val_binary_accuracy: 0.8870\n",
            "Epoch 164/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.0812 - binary_accuracy: 0.9689 - val_loss: 2.0441 - val_binary_accuracy: 0.8388\n",
            "Epoch 165/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.0831 - binary_accuracy: 0.9684 - val_loss: 2.8546 - val_binary_accuracy: 0.8882\n",
            "Epoch 166/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0830 - binary_accuracy: 0.9692 - val_loss: 1.8584 - val_binary_accuracy: 0.8310\n",
            "Epoch 167/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.0850 - binary_accuracy: 0.9671 - val_loss: 3.7306 - val_binary_accuracy: 0.8406\n",
            "Epoch 168/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0792 - binary_accuracy: 0.9691 - val_loss: 3.9643 - val_binary_accuracy: 0.8509\n",
            "Epoch 169/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0798 - binary_accuracy: 0.9704 - val_loss: 4.9950 - val_binary_accuracy: 0.8590\n",
            "Epoch 170/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0815 - binary_accuracy: 0.9692 - val_loss: 4.8104 - val_binary_accuracy: 0.8918\n",
            "Epoch 171/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0847 - binary_accuracy: 0.9696 - val_loss: 3.5689 - val_binary_accuracy: 0.8605\n",
            "Epoch 172/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0840 - binary_accuracy: 0.9670 - val_loss: 4.2512 - val_binary_accuracy: 0.8250\n",
            "Epoch 173/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0755 - binary_accuracy: 0.9714 - val_loss: 3.9304 - val_binary_accuracy: 0.8761\n",
            "Epoch 174/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0843 - binary_accuracy: 0.9669 - val_loss: 3.2421 - val_binary_accuracy: 0.8479\n",
            "Epoch 175/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0805 - binary_accuracy: 0.9714 - val_loss: 3.3724 - val_binary_accuracy: 0.8575\n",
            "Epoch 176/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0854 - binary_accuracy: 0.9683 - val_loss: 2.9282 - val_binary_accuracy: 0.8575\n",
            "Epoch 177/200\n",
            "104/104 [==============================] - 1s 12ms/step - loss: 0.0839 - binary_accuracy: 0.9701 - val_loss: 3.3651 - val_binary_accuracy: 0.8617\n",
            "Epoch 178/200\n",
            "104/104 [==============================] - 1s 12ms/step - loss: 0.0868 - binary_accuracy: 0.9662 - val_loss: 3.5864 - val_binary_accuracy: 0.8785\n",
            "Epoch 179/200\n",
            "104/104 [==============================] - 1s 12ms/step - loss: 0.0878 - binary_accuracy: 0.9665 - val_loss: 5.7001 - val_binary_accuracy: 0.8779\n",
            "Epoch 180/200\n",
            "104/104 [==============================] - 1s 12ms/step - loss: 0.0848 - binary_accuracy: 0.9672 - val_loss: 3.9360 - val_binary_accuracy: 0.8527\n",
            "Epoch 181/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.0901 - binary_accuracy: 0.9687 - val_loss: 3.6687 - val_binary_accuracy: 0.8406\n",
            "Epoch 182/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.0817 - binary_accuracy: 0.9711 - val_loss: 4.2223 - val_binary_accuracy: 0.8635\n",
            "Epoch 183/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.0806 - binary_accuracy: 0.9681 - val_loss: 4.4666 - val_binary_accuracy: 0.8292\n",
            "Epoch 184/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0778 - binary_accuracy: 0.9705 - val_loss: 4.9096 - val_binary_accuracy: 0.8280\n",
            "Epoch 185/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.0858 - binary_accuracy: 0.9682 - val_loss: 4.7291 - val_binary_accuracy: 0.8485\n",
            "Epoch 186/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0780 - binary_accuracy: 0.9733 - val_loss: 4.3804 - val_binary_accuracy: 0.8304\n",
            "Epoch 187/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0809 - binary_accuracy: 0.9693 - val_loss: 4.2026 - val_binary_accuracy: 0.8250\n",
            "Epoch 188/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0773 - binary_accuracy: 0.9731 - val_loss: 3.7244 - val_binary_accuracy: 0.8292\n",
            "Epoch 189/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.0860 - binary_accuracy: 0.9674 - val_loss: 4.8369 - val_binary_accuracy: 0.8755\n",
            "Epoch 190/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0813 - binary_accuracy: 0.9702 - val_loss: 3.3803 - val_binary_accuracy: 0.8485\n",
            "Epoch 191/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.0807 - binary_accuracy: 0.9684 - val_loss: 2.9438 - val_binary_accuracy: 0.8431\n",
            "Epoch 192/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0805 - binary_accuracy: 0.9693 - val_loss: 3.2527 - val_binary_accuracy: 0.8707\n",
            "Epoch 193/200\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.0849 - binary_accuracy: 0.9692 - val_loss: 3.1499 - val_binary_accuracy: 0.8325\n",
            "Epoch 194/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0808 - binary_accuracy: 0.9695 - val_loss: 3.1265 - val_binary_accuracy: 0.8437\n",
            "Epoch 195/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0827 - binary_accuracy: 0.9656 - val_loss: 4.3420 - val_binary_accuracy: 0.8358\n",
            "Epoch 196/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0860 - binary_accuracy: 0.9662 - val_loss: 2.6610 - val_binary_accuracy: 0.8665\n",
            "Epoch 197/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0825 - binary_accuracy: 0.9684 - val_loss: 3.2732 - val_binary_accuracy: 0.8370\n",
            "Epoch 198/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0794 - binary_accuracy: 0.9681 - val_loss: 4.3183 - val_binary_accuracy: 0.8406\n",
            "Epoch 199/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0749 - binary_accuracy: 0.9719 - val_loss: 3.9273 - val_binary_accuracy: 0.8545\n",
            "Epoch 200/200\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0795 - binary_accuracy: 0.9693 - val_loss: 5.1276 - val_binary_accuracy: 0.8719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TESTING DATA : SEPERATING FEATURES AND LABELS\n",
        "\n",
        "feature = testing_dataset.drop([\"class\",\"index\"], axis = 1)\n",
        "label = testing_dataset[\"class\"]\n",
        "# SCALING\n",
        "\n",
        "scaler = StandardScaler()\n",
        "feature = scaler.fit_transform(feature)\n",
        "# ONE HOT ENCODING\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label = label_encoder.fit_transform(label)\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "label = label.reshape(len(label), 1)\n",
        "label = onehot_encoder.fit_transform(label)"
      ],
      "metadata": {
        "id": "t20INzbfIdct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATION\n",
        "pred = model.predict(feature)\n",
        "\n",
        "#NORMALIZING OUTPUT\n",
        "\n",
        "pred = np.array(list(map(lambda a : np.argmax(a),pred)))\n",
        "\n",
        "#NORMALIZING TARGET\n",
        "\n",
        "label = np.array(list(map(lambda a : np.argmax(a),label)))\n",
        "\n",
        "# PREDICTION - TARGET COMPARISON\n",
        "\n",
        "f = plt.figure()\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(label)\n",
        "plt.title(\"target\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(pred)\n",
        "plt.title(\"prediction\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "g1Fjg1E4MOvC",
        "outputId": "2a16e484-1f67-4e15-aa1b-8e2dd48674b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65/65 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'prediction')"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVTUlEQVR4nO3de5BmdZ3f8fdnmQBBDdcJi8NlMEu0cGtdyBSQmFJXqFXA3WETpEBXBxgza4JmE0wpLptgjO7iVioo0cIlgGLWDLDEDeiyFwQsKxdwByUgEJYBwZlxgJFbVCKCfvPH8xt96Omme/p5+ja/96uqq8/5nd8559uHX8+nz+0hVYUkqU8/t9AFSJIWjiEgSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0DSopHkoSQntOnfSXLZLLdzd5I3jLW4XZQhsEgMD/6e9i1Npap+r6reNV2/JJ9N8pEJ6766qr4yZ8XtQgyBXUCS3Ra6BmmiJMsWugZNzxBYBJL8Z+BQ4ItJvp/k/Un+OMkjSZ5O8tUkrx7q/9kklyS5IckPgF9JcnSSbyT5Xlv36uG/jpK8JckdSZ5K8j+T/NJU+57nH19LTDtz/GCSe5I8meQzSfZM8oYkm5N8IMkjwGeS/FyS85I8kOTxJNck2W9oW+9I8nBbdv6E/XwoyR8Nzf/DNnafSrIpyZlJ1gFvB97fxu8Xh2rcfllpjyQfT/Kd9vXxJHu0Zdtrfl+Sx5JsTXLWPBzGRcMQWASq6h3At4Ffq6qXVtUfAH8GHAH8beDrwOcnrPY24KPAy4CvAX8CfBbYD1gP/Mb2jkmOAq4AfgvYH/hD4Poke0yxb2k6bwfeBPwd4O8Cv9vaf57BGDwMWAe8FzgFeD3wcuBJ4FMASY4ELgHe0ZbtDxw82c6SHMbgd+I/AsuBXwbuqKpLGfxu/EEbv782yernA8e1dV4DHDNU7/aa9wZWAGuBTyXZd6eOxhJmCCxSVXVFVX2vqp4FPgS8JsneQ12uq6r/UVU/YTC4lwEXV9VzVfUFBsGw3TrgD6vqtqr6cVVdCTzL4BdDmo1PVtWmqnqCwR8jZ7T2nwAXVNWzVfX/gHcD51fV5qGxfGq7VHQq8KWq+mpb9q/b+pN5G/DlqlrfxvjjVXXHDGt9O/DhqnqsqrYB/5ZB8Gz3XFv+XFXdAHwfeOUMt73kec1uEWrX+D8KvJXBXz3bfzEOAJ5u05uGVnk5sKVe+GmAw8sPA9Ykee9Q2+5tPWk2hsfXw/xsLG2rqh8OLTsM+JMkw/+4/xg4sK3z0+1U1Q+SPD7F/g4BHphlrS9vNU5WL8DjVfX80PwzwEtnua8lxzOBxWP4H/C3AauBExicpq5s7Zmi/1ZgRZLh5YcMTW8CPlpV+wx97VVV6yfZljQTw+PrUOA7bXriWNoEnDhh7O1ZVVsYjNufbifJXgwuCU1mE4NLT5OZbvx+h0EYTVZv9wyBxeNR4BVt+mUMLtc8DuwF/N406/4vBn9dvSfJsiSrGVz33O4/Ae9OcmwGXpLk5CQvm2Tf0kyck+TgdpP3fODqKfp9Gvhou6ZPkuVtfAJcC7yl3fDdHfgwU/+b9HnghCSntTG+f5JfbsumG7/rgd9t+z4A+DfAH71I/64YAovH7zMYqE8xuLH2MLAFuAe49cVWrKofAf+IwU2tp4DfBL7EIEioqg3APwE+yeDG3EbgzMn2neRfje9H0i7svwB/CTzI4DLNR6bo9wngeuAvk3yPwVg+FqCq7gbOadvaymBsbp5sI1X1beAk4H3AE8AdDG7yAlwOHNnG73+bZPWPABuAO4G7GDxoMVW93Yn/U5ldU5LbgE9X1WcWuhbtWpI8BLyrqr680LVodJ4J7CKSvD7Jz7dT5TXALwF/vtB1SVrcfDpo1/FK4BrgJQxO0U+tqq0LW5Kkxc7LQZLUMS8HSVLHFvXloAMOOKBWrly50GVoF3b77bd/t6qWz/d+HduaSzszrhd1CKxcuZINGzYsdBnahSV5ePpe4+fY1lzamXHt5SBJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwBSerYon5jWBq28rw/ndV6D1148pgrmVu9/JxaHDwTkKSOGQKS1DFDQJI6ZghIUscMAUnqmCEgSR0zBCSpY0v2PQGfpZak0U17JpDkiiSPJfnmUNt+SW5Mcn/7vm9rT5KLk2xMcmeSo4fWWdP6359kzdz8OJKknTGTy0GfBd48oe084KaqOgK4qc0DnAgc0b7WAZfAIDSAC4BjgWOAC7YHhyRp4UwbAlX1VeCJCc2rgSvb9JXAKUPtn6uBW4F9khwEvAm4saqeqKongRvZMVgkSfNstjeGD6yqrW36EeDANr0C2DTUb3Nrm6p9B0nWJdmQZMO2bdtmWZ4kaSZGfjqoqgqoMdSyfXuXVtWqqlq1fPnycW1WkjSJ2YbAo+0yD+37Y619C3DIUL+DW9tU7ZKkBTTbELge2P6EzxrguqH2d7anhI4Dnm6Xjf4C+NUk+7Ybwr/a2iRJC2ja9wSSrAfeAByQZDODp3wuBK5JshZ4GDitdb8BOAnYCDwDnAVQVU8k+XfAX7V+H66qiTebJUnzbNoQqKozplh0/CR9Czhniu1cAVyxU9VJkuaUHxshSR0zBCSpY4aAJHXMEJCkjhkC6tbZZ58N8Bo/HFE9MwTUrTPPPBPg/gnNfjiiumIIqFuve93rAJ6f0OyHI6orhoD0Qn44orpiCEhT8MMR1QNDQHohPxxRXTEEpBfywxHVlSX7P5qXRnXGGWcAvIrBE6B+OKK6ZAioW+vXr+eqq666s6pWTVjkhyOqG14OkqSOGQKS1DFDQJI6ZghIUscMAUnqmE8HSdICWnnen85qvYcuPHks+/dMQJI6ZghIUscMAUnqmCEgSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6thIIZDkXya5O8k3k6xPsmeSw5PclmRjkquT7N767tHmN7blK8fxA0iSZm/WIZBkBfDPgVVV9YvAbsDpwMeAi6rqF4AngbVtlbXAk639otZPkrSARr0ctAz4m0mWAXsBW4E3Ate25VcCp7Tp1W2etvz4JBlx/5KkEcw6BKpqC/DvgW8z+Mf/aeB24Kmqer512wysaNMrgE1t3edb//0nbjfJuiQbkmzYtm3bbMuTJM3AKJeD9mXw1/3hwMuBlwBvHrWgqrq0qlZV1arly5ePujlJ0osY5XLQCcC3qmpbVT0HfAF4LbBPuzwEcDCwpU1vAQ4BaMv3Bh4fYf+SpBGNEgLfBo5Lsle7tn88cA9wC3Bq67MGuK5NX9/mactvrqoaYf+SpBGNck/gNgY3eL8O3NW2dSnwAeDcJBsZXPO/vK1yObB/az8XOG+EuiVJYzDS/2O4qi4ALpjQ/CBwzCR9fwi8dZT9SZLGyzeGJaljhoA0Cd+GVy8MAWkC34ZXTwwBaXK+Da8uGALSBL4Nr54YAtIEvg2vnhgC0o58G17dMASkHfk2vLphCEgT+Da8ejLSG8PSrsq34dULzwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwBSeqYISBJHTMEJKljhoAkdcwQkKSOGQKS1DFDQJI6ZghIUscMAUnqmCEgSR0zBCSpY4aAJHXMEJCkjhkCktSxkUIgyT5Jrk3yf5Lcm+TvJ9kvyY1J7m/f9219k+TiJBuT3Jnk6PH8CJKk2Rr1TOATwJ9X1auA1wD3AucBN1XVEcBNbR7gROCI9rUOuGTEfUuSRjTrEEiyN/A64HKAqvpRVT0FrAaubN2uBE5p06uBz9XArcA+SQ6adeWSpJGNciZwOLAN+EySbyS5LMlLgAOramvr8whwYJteAWwaWn9za3uBJOuSbEiyYdu2bSOUJ0mazighsAw4Grikqo4CfsDPLv0AUFUF1M5stKourapVVbVq+fLlI5QnSZrOKCGwGdhcVbe1+WsZhMKj2y/ztO+PteVbgEOG1j+4tUmSFsisQ6CqHgE2JXllazoeuAe4HljT2tYA17Xp64F3tqeEjgOeHrpsJElaAMtGXP+9wOeT7A48CJzFIFiuSbIWeBg4rfW9ATgJ2Ag80/pKkhbQSCFQVXcAqyZZdPwkfQs4Z5T9SfMlyT7AZcAvMrivdTZwH3A1sBJ4CDitqp5MEgaPS5/E4A+cM6vq6wtQtrTTfGNYmpzvwKgLhoA0ge/AqCeGgLQj34FRNwwBaUe+A6NuGALSjnwHRt0wBKQJfAdGPRn1PQFpV+U7MOqCISBNwndg1AsvB0lSxwwBSeqYISBJHTMEJKljhoAkdcwQkKSOGQKS1DFDQJI6ZghIUscMAUnqmCEgSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI6NHAJJdkvyjSRfavOHJ7ktycYkVyfZvbXv0eY3tuUrR923JGk04zgT+G3g3qH5jwEXVdUvAE8Ca1v7WuDJ1n5R6ydJWkAjhUCSg4GTgcvafIA3Ate2LlcCp7Tp1W2etvz41l+StEBGPRP4OPB+4Cdtfn/gqap6vs1vBla06RXAJoC2/OnW/wWSrEuyIcmGbdu2jVieJOnFzDoEkrwFeKyqbh9jPVTVpVW1qqpWLV++fJybliRNMMqZwGuBX0/yEHAVg8tAnwD2SbKs9TkY2NKmtwCHALTlewOPj7B/aU750IN6MOsQqKoPVtXBVbUSOB24uareDtwCnNq6rQGua9PXt3na8purqma7f2ke+NCDdnlz8Z7AB4Bzk2xkcM3/8tZ+ObB/az8XOG8O9i2NhQ89qBfLpu8yvar6CvCVNv0gcMwkfX4IvHUc+5PmwfaHHl7W5mf80EOS7Q89fHd4g0nWAesADj300DktXpop3xiWJvChB/VkLGcC0i5m+0MPJwF7An+LoYce2tnAZA89bPahBy01nglIE/jQg3piCEgz50MP2uV4OUh6ET70oF2dZwKS1DFDQJI6ZghIUscMAUnqmCEgSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwBSeqYISBJHTMEJKljhoAkdcwQkKSOGQKS1LFZh0CSQ5LckuSeJHcn+e3Wvl+SG5Pc377v29qT5OIkG5PcmeTocf0QkqTZGeVM4HngfVV1JHAccE6SI4HzgJuq6gjgpjYPcCJwRPtaB1wywr4lSWMw6xCoqq1V9fU2/T3gXmAFsBq4snW7EjilTa8GPlcDtwL7JDlo1pVLc8SzXPVkLPcEkqwEjgJuAw6sqq1t0SPAgW16BbBpaLXNrW3ittYl2ZBkw7Zt28ZRnrSzPMtVN0YOgSQvBf4r8C+q6v8OL6uqAmpntldVl1bVqqpatXz58lHLk3aaZ7nqyUghkORvMAiAz1fVF1rzo9t/Adr3x1r7FuCQodUPbm3SouVZrnZ1ozwdFOBy4N6q+g9Di64H1rTpNcB1Q+3vbNdPjwOeHvqFkhYdz3LVg2UjrPta4B3AXUnuaG2/A1wIXJNkLfAwcFpbdgNwErAReAY4a4R9S3Pqxc5yq2qrZ7naVcw6BKrqvwOZYvHxk/Qv4JzZ7k+aLzM4y72QHc9y35PkKuBYPMvVEjLKmYC0q/IsV90wBKQJPMtVT/zsIEnqmCEgSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwBSeqYISBJHTMEJKljhoAkdcwQkKSOGQKS1DFDQJI6ZghIUscMAUnqmCEgSR0zBCSpY4aAJHVs3kMgyZuT3JdkY5Lz5nv/0lxwXGupmtcQSLIb8CngROBI4IwkR85nDdK4Oa61lM33mcAxwMaqerCqfgRcBaye5xqkcXNca8laNs/7WwFsGprfDBw73CHJOmBdm/1+kvum2NYBwHd3toB8bGfXmJFZ1TIHFksdsIhqycdetJbDxrCLacc1LMmxvWj+G2ItOxjXuJ7vEJhWVV0KXDpdvyQbqmrVPJQ0rcVSy2KpA6xlMkttbC+WOsBa5rKO+b4ctAU4ZGj+4NYmLWWOay1Z8x0CfwUckeTwJLsDpwPXz3MN0rg5rrVkzevloKp6Psl7gL8AdgOuqKq7Z7m5aU+r59FiqWWx1AEd1TLmcQ2L59gtljrAWiYzljpSVePYjiRpCfKNYUnqmCEgSR1blCEw3Sv4SfZIcnVbfluSlUPLPtja70vypjmu49wk9yS5M8lNSQ4bWvbjJHe0r5FvEs6gljOTbBva57uGlq1Jcn/7WjMPtVw0VMdfJ3lqaNnYjkuSK5I8luSbUyxPkotbnXcmOXpo2ViPyQzrXRTjeoa1dDe2ux3XVbWovhjcWHsAeAWwO/C/gSMn9PlnwKfb9OnA1W36yNZ/D+Dwtp3d5rCOXwH2atP/dHsdbf7783xMzgQ+Ocm6+wEPtu/7tul957KWCf3fy+BG6Vwcl9cBRwPfnGL5ScCfAQGOA26bi2OylMa1Y9txPfFrMZ4JzOQV/NXAlW36WuD4JGntV1XVs1X1LWBj296c1FFVt1TVM232VgbPh8+FUT6W4E3AjVX1RFU9CdwIvHkeazkDWD/C/qZUVV8FnniRLquBz9XArcA+SQ5i/MdkJhbLuJ5RLR2O7W7H9WIMgclewV8xVZ+qeh54Gth/huuOs45haxmk83Z7JtmQ5NYkp8yyhp2t5R+308Nrk2x/eWmcx2SnttcuIRwO3DzUPM7jMp2pah33MRmllkn7zOG4nmktw3oY292O60X3sRFLUZLfBFYBrx9qPqyqtiR5BXBzkruq6oE5LOOLwPqqejbJbzH4i/KNc7i/mTgduLaqfjzUNt/HRSNwbE9qlxrXi/FMYCav4P+0T5JlwN7A4zNcd5x1kOQE4Hzg16vq2e3tVbWlfX8Q+Apw1CzrmFEtVfX40P4vA/7ezvwc46xlyOlMOGUe83GZzlS1LsTHPCyWcT3TWnob2/2O63HdzBjjTZFlDG5oHM7PbtC8ekKfc3jhDbRr2vSreeENtAeZ/Y3hmdRxFIObSUdMaN8X2KNNHwDcz4vcZBpTLQcNTf8GcGv97GbRt1pN+7bp/eayltbvVcBDtBcS5+K4tO2sZOobaCfzwhtoX5uLY7KUxrVj23G9w/bmcuCPcABOAv66DcLzW9uHGfxFArAn8McMbpB9DXjF0Lrnt/XuA06c4zq+DDwK3NG+rm/t/wC4qw2ku4C183BMfh+4u+3zFuBVQ+ue3Y7VRuCsua6lzX8IuHDCemM9Lgz+GtsKPMfg+uda4N3Au9vyMPifvTzQ9rdqro7JUhrXjm3H9fCXHxshSR1bjPcEJEnzxBCQpI4ZApLUMUNAkjpmCEhSxwwBSeqYISBJHfv/Z7gH7510LkoAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFUSION MATRIX\n",
        "matrix = confusion_matrix(label, pred)\n",
        "print(\"True negative :\",matrix[0][0])\n",
        "print(\"False positive :\",matrix[0][1])\n",
        "print(\"False negative :\",matrix[1][0])\n",
        "print(\"True positive :\",matrix[1][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mgv49-YiWIL",
        "outputId": "0986d312-6f1f-4f47-b891-4c7b00763c91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True negative : 992\n",
            "False positive : 25\n",
            "False negative : 147\n",
            "True positive : 915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ACCURACY\n",
        "\n",
        "accuracy_score(label,pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Yx3zp2clMxu",
        "outputId": "5c2da6a4-5d0e-49ac-bd30-a62f07397b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9172679172679172"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVING MODEL\n",
        "\n",
        "model.save(\"malware_detection_model.h5\")"
      ],
      "metadata": {
        "id": "z2b-h0Yxnang"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}